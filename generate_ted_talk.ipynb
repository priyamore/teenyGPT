{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-03T01:28:09.120530Z","iopub.status.busy":"2024-10-03T01:28:09.120078Z","iopub.status.idle":"2024-10-03T01:28:10.220047Z","shell.execute_reply":"2024-10-03T01:28:10.218943Z","shell.execute_reply.started":"2024-10-03T01:28:09.120485Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/ted-talks/transcripts.csv\n","/kaggle/input/ted-talks/ted_main.csv\n","                                          transcript  \\\n","0  Good morning. How are you?(Laughter)It's been ...   \n","1  Thank you so much, Chris. And it's truly a gre...   \n","2  (Music: \"The Sound of Silence,\" Simon & Garfun...   \n","3  If you're here today â€” and I'm very happy that...   \n","4  About 10 years ago, I took on the task to teac...   \n","\n","                                                 url  \n","0  https://www.ted.com/talks/ken_robinson_says_sc...  \n","1  https://www.ted.com/talks/al_gore_on_averting_...  \n","2  https://www.ted.com/talks/david_pogue_says_sim...  \n","3  https://www.ted.com/talks/majora_carter_s_tale...  \n","4  https://www.ted.com/talks/hans_rosling_shows_t...  \n","Data has been combined and written to combined_transcripts.txt\n"]}],"source":["import numpy as np\n","import pandas as pd\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Load the CSV file\n","csv_file_path = '/kaggle/input/ted-talks/transcripts.csv'\n","df = pd.read_csv(csv_file_path)\n","print(df.head())\n","\n","text_data = df['transcript'].astype(str)  # Convert to string if necessary\n","\n","combined_text = '\\n'.join(text_data)\n","\n","# Write the combined text to a .txt file\n","output_file_path = 'combined_transcripts.txt'\n","with open(output_file_path, 'w', encoding='utf-8') as f:\n","    f.write(combined_text)\n","\n","print(f\"Data has been combined and written to {output_file_path}\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-03T01:28:10.222427Z","iopub.status.busy":"2024-10-03T01:28:10.222088Z","iopub.status.idle":"2024-10-03T01:28:14.257744Z","shell.execute_reply":"2024-10-03T01:28:14.256621Z","shell.execute_reply.started":"2024-10-03T01:28:10.222389Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["length of dataset in characters:  28221326\n","172\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","\n","\n","# ------------ hyperparameters ------------\n","batch_size = 128 # number of sequences for parallel processing\n","block_size = 256 # context length\n","emb_dim = 384 # size of embedding vector, say 32 for a vocabulary of 65\n","max_iters = 5000 # number of steps\n","l_rate = 3e-4\n","eval_interval = 500\n","eval_iters = 200\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","num_layers = 6\n","num_heads = 6\n","dropout = 0.2\n","# ------------------------------------------\n","\n","torch.manual_seed(1337)\n","\n","# Input\n","# Understand and analyse the input\n","with open('/kaggle/working/combined_transcripts.txt', 'r', encoding='utf-8') as f:\n","    text = f.read()\n","    \n","\n","print(\"length of dataset in characters: \", len(text))\n","\n","# unique chars in the datset\n","chars = sorted(list(set(text)))\n","vocab_size = len(chars)\n","print(vocab_size)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-03T01:28:14.259645Z","iopub.status.busy":"2024-10-03T01:28:14.259125Z","iopub.status.idle":"2024-10-03T01:28:21.076756Z","shell.execute_reply":"2024-10-03T01:28:21.075953Z","shell.execute_reply.started":"2024-10-03T01:28:14.259605Z"},"trusted":true},"outputs":[],"source":["# build lookup tables and tokenizer\n","stoi_lookup = {char: i for i, char in enumerate(chars)}  # . already in the dataset so no need to add it\n","itos_lookup = {i: char for i,char in enumerate(chars)}\n","\n","#tokenizer - convert raw text(strings) to seq of integers\n","# In practice, sub_words are used for tokenization, so for a sentence we will get only a few tokens\n","encode = lambda s: [stoi_lookup[char] for char in s]\n","decode = lambda ix: \"\".join(itos_lookup[i] for i in ix)\n","\n","\n","# tokenise the dataset and split it into train and val datasets\n","tokenised_out = torch.tensor(encode(text), dtype=torch.long)\n","train_w_end = int(0.9 * len(tokenised_out))\n","x_tr = tokenised_out[:train_w_end]\n","x_val = tokenised_out[train_w_end:]\n","\n","# ------------ data loader ------------\n","def get_batch(split):\n","    # minibatch construct\n","    data = x_tr if split == 'train' else x_val\n","    ix = torch.randint(len(data) - block_size, (batch_size,)) # high is set to len(data) - block_size so that we stay within the bounds\n","    x = torch.stack([data[i: i + block_size] for i in ix]) # stack and sliced rows, shape: (32, 8)\n","    y = torch.stack([data[i+1: i + (block_size+1)] for i in ix]) # stack for the next token\n","    x, y = x.to(device), y.to(device)\n","    return x, y\n","# ---------------------------------------\n","\n","@torch.no_grad() # dont calculate grads while calulating the loss\n","def estimate_loss():\n","    f_out = {}\n","    model.eval() # set the model mode to eval\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(eval_iters)\n","        # calculate the train and val losses for the eval iters\n","        for i in range(eval_iters):\n","            ix, iy = get_batch(split) # load the batch\n","            _, loss = model(ix, iy) # calculate the loss\n","            losses[i] = loss.item()\n","        f_out[split] = losses.mean() # avg loss for the eval iters\n","    \n","    model.train() # set the model mode back to train\n","    return f_out"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-03T01:28:21.078753Z","iopub.status.busy":"2024-10-03T01:28:21.078430Z","iopub.status.idle":"2024-10-03T02:24:49.615467Z","shell.execute_reply":"2024-10-03T02:24:49.614426Z","shell.execute_reply.started":"2024-10-03T01:28:21.078719Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["step 0: training loss 5.2522, validation loss 5.2551\n","step 500: training loss 1.9742, validation loss 1.9913\n","step 1000: training loss 1.5294, validation loss 1.5479\n","step 1500: training loss 1.3807, validation loss 1.3966\n","step 2000: training loss 1.3001, validation loss 1.3129\n","step 2500: training loss 1.2438, validation loss 1.2624\n","step 3000: training loss 1.1994, validation loss 1.2219\n","step 3500: training loss 1.1742, validation loss 1.1964\n","step 4000: training loss 1.1556, validation loss 1.1778\n","step 4500: training loss 1.1409, validation loss 1.1644\n","generated text:  \n"," But it's, it kind of you leave resonable. It's moject nature. Haterwest! It's staying a chip, which, a very state point revolutions, and they're kind of doing sharing, getting communication to the energy training model, go to just specultarily a very see of people testime they're finutions here. Two. This ism text, something as people get triphes at part of die-harged. This prime entergy is actually an execution of theorigin sphere. And this is the cave two deceptive there about the world: actu\n"]}],"source":["class Head(nn.Module):\n","    \"\"\"self-attention with a single head(communication channel)\"\"\"\n","    def __init__(self, head_size):\n","        super().__init__()\n","        self.key = nn.Linear(emb_dim, head_size, bias=False)\n","        self.query = nn.Linear(emb_dim, head_size, bias= False)\n","        self.value = nn.Linear(emb_dim, head_size, bias= False)\n","        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        B, T, C = x.shape\n","        K = self.key(x)\n","        Q = self.query(x)\n","        V = self.value(x)\n","        # calculate the relevance scores i.e weights\n","        weights = Q @ K.transpose(-1, -2)  * (C ** -0.5) # scaling factor - square root of the head_size \n","        weights = weights.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n","        weights = F.softmax(weights, dim=-1)\n","        weights = self.dropout(weights)\n","        # weighted agg of V\n","        f_out = weights @ V\n","        return f_out\n","\n","class MultiHead(nn.Module):\n","    \"\"\"Multiple Self Attentions in Parallel\"\"\"\n","    def __init__(self, num_heads, head_size):\n","        super().__init__()\n","        # register Heads as modules\n","        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","        self.projection = nn.Linear(emb_dim, emb_dim)\n","        self.dropout = nn.Dropout(dropout)\n","    \n","    def forward(self, x):\n","        # concatentae the outputs from multiple attention heads over C\n","        f_out = torch.cat([head(x) for head in self.heads], dim=-1)\n","        f_out = self.projection(f_out)\n","        f_out = self.dropout(f_out)\n","        return f_out\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, emb_dim):\n","        super().__init__()\n","        self.network = nn.Sequential(\n","            nn.Linear(emb_dim, 4 * emb_dim),\n","            nn.ReLU(),\n","        )\n","        self.projection = nn.Linear(4 * emb_dim, emb_dim)\n","        self.dropout = nn.Dropout(dropout)\n","    \n","    def forward(self, x):\n","        f_out = self.network(x)\n","        f_out = self.projection(f_out)\n","        f_out = self.dropout(f_out)\n","        return f_out\n","\n","class Block(nn.Module):\n","    \"\"\" Transformer Block - Multiheaded Attention followed by feed forward\"\"\"\n","\n","    def __init__(self, emb_dim, num_heads):\n","        super().__init__()\n","        head_size = emb_dim // num_heads\n","        # layer norm is applied before the transformation takes place(Unlike the Attention paper)\n","        self.layer_norm1 = nn.LayerNorm(emb_dim)\n","        self.layer_norm2 = nn.LayerNorm(emb_dim)\n","        # communication\n","        self.multiheads = MultiHead(num_heads=num_heads, head_size=head_size)\n","        self.ffwd = FeedForward(emb_dim=emb_dim)\n","        \n","    def forward(self, x):\n","        # add skip connections by adding input back to each layer\n","        x = x + self.multiheads(self.layer_norm1(x))\n","        x = x + self.ffwd(self.layer_norm2(x))\n","        return x\n","    \n","\n","class BigramLM(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # emebedding table mapping each token to a vector\n","        self.token_embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=emb_dim) \n","        # positional embedding table to capture the postion of each time step\n","        self.pos_embeddings = nn.Embedding(block_size, emb_dim)\n","        self.blocks = nn.ModuleList([Block(emb_dim, num_heads) for _ in range(num_layers)])\n","        self.blocks = nn.Sequential(*self.blocks) # make sure to unpack the list\n","        self.layer_norm = nn.LayerNorm(emb_dim) # final layer norm\n","        self.bi_lm_head = nn.Linear(emb_dim, vocab_size) #language model head\n","\n","    def forward(self, ix, target=None):\n","        B, T = ix.shape\n","        token_emb = self.token_embeddings(ix)                           # (B, T, C)\n","        pos_emb = self.pos_embeddings(torch.arange(T, device=device))   # idx of the each time step results to (T, C) \n","        x = token_emb + pos_emb                                         # go to the position by adding pos_emb, results to (B, T, C)\n","        x = self.blocks(x) # apply self attention\n","        x = self.layer_norm(x)\n","        logits = self.bi_lm_head(x) # (B, T, vocab_size)\n","\n","        if target is not None:\n","            B, T, C = logits.shape\n","            # 2. calculate the loss - nll/cross_entropy\n","            loss = F.cross_entropy(logits.view(B*T, C), target.view(B*T))            # cross_entropy only accepts ((C), (N,C) (N,C)), N - batch_size \n","        else:\n","            loss = None\n","        return logits, loss\n","\n","    def generate(self, ix, max_new_tokens):\n","        # ix is (B, T) i.e (batch, time) => (32, 8)\n","        for _ in range(max_new_tokens):\n","            ix_cond = ix[:, -block_size:] # the ix has to be within the bounds of the time step\n","            logits, _ = self(ix_cond) # get the targets\n","            logits = logits[:, -1, :] # what comes next in the sequence? the last char in the time dimension i.e context, (B, C)\n","            probs = F.softmax(logits, dim=-1) #apply softmax on the C dimension to get the probs for dim embeddings\n","            next_ix = torch.multinomial(probs, num_samples=1) # sampling for the next char from the dist\n","            ix = torch.cat((ix, next_ix), dim=1) # add the next token to  input i.e running generatio\n","            \n","        return ix\n","\n","bi_model = BigramLM()\n","model = bi_model.to(device)\n","\n","# ------------ training ------------\n","# optimiser for training the BigramML\n","optimizer = torch.optim.AdamW(bi_model.parameters(), lr=l_rate) # Adam instead of SGD, learning rate = 0.001\n","\n","for step in range(max_iters):\n","    if step % eval_interval == 0:\n","        losses = estimate_loss()\n","        print(f\"step {step}: training loss {losses['train']:.4f}, validation loss {losses['val']:.4f}\")\n","\n","    xb, yb = get_batch('train')\n","    # forward pass\n","    logits, loss = model(xb, yb)\n","    # backward pass\n","    optimizer.zero_grad(set_to_none=True) # set grad= 0 to clear the grads from the prev steps as usual\n","    loss.backward()\n","    # update the model params\n","    optimizer.step()\n","# ------------------------------------\n","\n","# sample/generate from the model\n","ix = torch.zeros((1, 1), dtype=torch.long, device = device) # start from a newline char(0)\n","generated_ix = model.generate(ix, max_new_tokens=500)\n","print('generated text: ', decode(generated_ix[0].tolist()))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":2405,"sourceId":4437,"sourceType":"datasetVersion"}],"dockerImageVersionId":30776,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
